# Server Configuration
server.port=8080

# LangChain4j OpenAI Configuration
# You can replace base-url with DeepSeek or Qwen API URL if compatible
langchain4j.open-ai.chat-model.api-key=demo
langchain4j.open-ai.chat-model.base-url=https://api.openai.com/v1
langchain4j.open-ai.chat-model.model-name=gpt-3.5-turbo
langchain4j.open-ai.chat-model.log-requests=true
langchain4j.open-ai.chat-model.log-responses=true
